# 深度学习笔记

## 1.概述 

1.1 深度学习在算法性能方面取得诸多成果，归纳有三个方面：

    · Dropout等防止过拟合的方法
    · 新的激活函数
    · 增加预训练方法

1.2 神经网络发展三阶段：
    
    · M-P模型（1943） 、感知机（1958）
    · 神经认知机（1980）、Hopfield模型（1982）、BP算法（1986）、卷积神经网络（1989）
    · 在卷积神经网络中引入ReLU（2012）

<br>

## 2.神经网络
### 2.1 M-P模型  

$$
    y= f(\sum_{i=1}^{n} w_ix_i - h) = \begin{cases}
    1 & \sum_{i=1}^{n} w_ix_i - h>0 \\
    0 & \sum_{i=1}^{n} w_ix_i - h \leq 0
    \end{cases}
$$
$$h:阈值$$

M-P模型没有学习能力，因为w和h都是固定的。    
M-P模型规定：输入输出只能为0或1。

### 2.2 前馈神经网络

最简单的神经网络，由输入层、隐藏层和输出层组成，每层的神经元只与前一层的神经元相连。

前馈神经网络有两种：

    · 反向传播网络（BP，感知机就属于BP）
    · 径向基网络（RBF）

### 2.3 感知机
#### 2.3.1 单层感知机

$$
    y= f(\sum_{i=1}^{n} w_ix_i - h) = \begin{cases}
    1 & \sum_{i=1}^{n} w_ix_i - h>0 \\
    0 & \sum_{i=1}^{n} w_ix_i - h \leq 0
    \end{cases}
$$

从结构上看，单层感知机与M-P模型是一样的，但两者有本质区别，M-P模型的连接权重参数w和阈值参数h是事先设定的，不能改变；而感知机的w和h可以通过训练自动修正。  

注意：

    · 感知机的输入也只能为0或1。
    · 单层感知机无法解决线性不可分问题（异或问题）

#### 2.3.2 多层感知机

添加中间层（可以不止一层），解决了异或问题，但还是无法解决所有的线性不可分问题，解决线性不可分问题通常需要通过核函数映射到高维空间。

### 2.4 神经网络的学习

神经网络的结构是事先设计好的，但还有大量参数（权值w和阈值h）需要通过学习确定。

学习方式主要有三种：

    · 监督学习
    · 无监督学习
    · 强化学习

#### 2.4.1 损失函数

用来计算实际输出值与和期望输出值之间的差距的函数称为损失函数。

通常使用的有两种：

（1）对于多分类问题，一般使用交叉熵损失函数。

$$ 
E=-\frac {1}{n}\sum_{i=1}^{n} \sum_{j=1}^{m} r_{ij}\ln{y_{ij}}
$$
$$ r_{ij}:第i组数据的第j个元素的期望输出值，只取0或1 $$
$$ y_{ij}:第i组数据的第j个元素的实际输出值，在[0,1]之间取值 $$

    可见，交叉熵误差值越小，结果越好。  
    交叉熵误差值只与正确分类的输出结果有关（当分类正确时，r值=1）

（2）对于递归问题，通常使用均方差（最小二乘）损失函数。

$$
E=\frac {1}{2}\sum_{i=1}^{n} (r_i - y_i)^2
$$

#### 2.4.2 激活函数
激活函数提供了神经网络非线性建模的能力。如果没有激活函数，神经网络每层的输入只是上一层输出的线性函数。

激活函数的性质：

    · 可导性
    · 单调性
    · 非线性性
    · 值域最好在[0,1]之间，否则还要通过softmax函数来计算分类的概率。

常见的激活函数：  
（1）阶梯函数

$$
f(x)=\begin{cases}
0 & x \leq 0 \\
1 & x >0 \\
\end{cases}
$$

（2）sigmoid函数

$$ f(x)=\frac{1}{1+e^{-x}} $$

（3）tanh函数

$$ f(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} $$

（4）ReLU函数

$$ f(x)=\max(0,x) $$

#### 2.4.3 似然函数

似然函数是计算实际输出与期望输出之间接近程度的函数。

常见的似然函数：  
（1）softmax函数，常用于多分类问题。

$$ f(x)=\frac{e^{x}}{\sum_{i=1}^{n} e^{x_i}} $$

    softmax函数也可以看做是输出层的激活函数。

（2）线性输出函数，常用于递归问题。

$$ f(x)=x $$

    输出层各单元的输出值应介于[0,1]之间。

#### 2.4.4 梯度与梯度下降

